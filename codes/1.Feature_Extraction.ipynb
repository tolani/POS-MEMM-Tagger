{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction : to vectorize given words \n",
    "\n",
    "* we are converting each word to a vectorized form which is a binary vector ( containing only 0s and 1s )\n",
    "* Each feature/column is a binary question. e.g. is first letter capitalized or not ? ( Yes = 1 / No = 0 ) \n",
    "* We are considering mainly suffix , prefix , prev and next context , some english rules of words as features\n",
    "* At the end we will store this feature dataframe to a csv file , for future use : as this code takes time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211727, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data_for_postagging/postrain', sep = \" \")\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>capitalize</th>\n",
       "      <th>digit_first</th>\n",
       "      <th>s_dig__e_alpha</th>\n",
       "      <th>p_anti</th>\n",
       "      <th>p_pre</th>\n",
       "      <th>p_un</th>\n",
       "      <th>p_dis</th>\n",
       "      <th>p_inter</th>\n",
       "      <th>...</th>\n",
       "      <th>s_ed_ing</th>\n",
       "      <th>s_tion_ion</th>\n",
       "      <th>s_est</th>\n",
       "      <th>s_less</th>\n",
       "      <th>s_e_es</th>\n",
       "      <th>s_en</th>\n",
       "      <th>s_ly</th>\n",
       "      <th>s_er</th>\n",
       "      <th>s_'s_s'</th>\n",
       "      <th>prev_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  tag capitalize digit_first s_dig__e_alpha p_anti p_pre p_un p_dis  \\\n",
       "0  NaN  NaN        NaN         NaN            NaN    NaN   NaN  NaN   NaN   \n",
       "1  NaN  NaN        NaN         NaN            NaN    NaN   NaN  NaN   NaN   \n",
       "2  NaN  NaN        NaN         NaN            NaN    NaN   NaN  NaN   NaN   \n",
       "3  NaN  NaN        NaN         NaN            NaN    NaN   NaN  NaN   NaN   \n",
       "4  NaN  NaN        NaN         NaN            NaN    NaN   NaN  NaN   NaN   \n",
       "\n",
       "  p_inter    ...    s_ed_ing s_tion_ion s_est s_less s_e_es s_en s_ly s_er  \\\n",
       "0     NaN    ...         NaN        NaN   NaN    NaN    NaN  NaN  NaN  NaN   \n",
       "1     NaN    ...         NaN        NaN   NaN    NaN    NaN  NaN  NaN  NaN   \n",
       "2     NaN    ...         NaN        NaN   NaN    NaN    NaN  NaN  NaN  NaN   \n",
       "3     NaN    ...         NaN        NaN   NaN    NaN    NaN  NaN  NaN  NaN   \n",
       "4     NaN    ...         NaN        NaN   NaN    NaN    NaN  NaN  NaN  NaN   \n",
       "\n",
       "  s_'s_s' prev_word  \n",
       "0     NaN       NaN  \n",
       "1     NaN       NaN  \n",
       "2     NaN       NaN  \n",
       "3     NaN       NaN  \n",
       "4     NaN       NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final dataframe : it ll be our data matrix \n",
    "\n",
    "final= pd.DataFrame(index = range(211730) , columns = ['word', 'tag', 'capitalize', \n",
    "                                                       'digit_first', \n",
    "                                                       's_dig__e_alpha', 'p_anti', \n",
    "                                                       'p_pre', 'p_un',\n",
    "                                                       'p_dis', 'p_inter', 'p_mis', \n",
    "                                                       'p_non', 'p_over_under',\n",
    "                                                       'p_in_im', 'p_en_em','s_able',\n",
    "                                                       's_al_ial', \n",
    "                                                      's_ed_ing','s_tion_ion','s_est',\n",
    "                                                      's_less', 's_e_es', \n",
    "                                                      's_en','s_ly','s_er','s_\\'s_s\\'',\n",
    "                                                      'prev_word'])\n",
    "\n",
    "#prev_word represents that prev word is a, an or the\n",
    "final\n",
    "\n",
    "#df = pd.DataFrame(index=range(numRows),columns=range(numCols))\n",
    "\n",
    "#final['word'][2] = 1\n",
    "final.shape\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting feautures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in df.index.values:\n",
    "    \n",
    "    j += 1\n",
    "    \n",
    "   # if(j > 10):\n",
    "   #     break\n",
    "    \n",
    "    if df.word[i][0].isupper():\n",
    "        final['capitalize'][i] = 1\n",
    "    else:\n",
    "        final['capitalize'][i] = 0\n",
    "        \n",
    "    if df.word[i][0].isdigit():\n",
    "        final['digit_first'][i] = 1\n",
    "    else:\n",
    "        final['digit_first'][i] = 0\n",
    "        \n",
    "    if df.word[i][0].isdigit() and df.word[i][-1].isalpha():\n",
    "        final['s_dig__e_alpha'][i] = 1\n",
    "    else:\n",
    "        final['s_dig__e_alpha'][i] = 0\n",
    "        \n",
    "    if df.word[i].startswith('anti'):\n",
    "        final['p_anti'][i] = 1\n",
    "    else:\n",
    "        final['p_anti'][i] = 0\n",
    "        \n",
    "    if df.word[i].startswith('pre'):\n",
    "        final['p_pre'][i] = 1\n",
    "    else:\n",
    "        final['p_pre'][i] = 0\n",
    "        \n",
    "    if df.word[i].startswith('un'):\n",
    "        final['p_un'][i] = 1\n",
    "    else:\n",
    "        final['p_un'][i] = 0\n",
    "    if df.word[i].startswith('dis'):\n",
    "        final['p_dis'][i] = 1\n",
    "    else:\n",
    "        final['p_dis'][i] = 1\n",
    "    if df.word[i].startswith('inter'):\n",
    "        final['p_inter'][i] = 1\n",
    "    else:\n",
    "        final['p_inter'][i] = 0\n",
    "    if df.word[i].startswith('mis'):\n",
    "        final['p_mis'][i] = 1\n",
    "    else:\n",
    "        final['p_mis'][i] = 0\n",
    "    if df.word[i].startswith('non'):\n",
    "        final['p_non'][i] = 1\n",
    "    else:\n",
    "        final['p_non'][i] = 0\n",
    "        \n",
    "    if df.word[i].startswith('over') or df.word[i].startswith('under'):\n",
    "        final['p_over_under'][i] = 1\n",
    "    else:\n",
    "        final['p_over_under'][i] = 1\n",
    "        \n",
    "    if df.word[i].startswith('in') or df.word[i].startswith('im'):\n",
    "        final['p_in_im'][i] = 1\n",
    "    else:\n",
    "        final['p_in_im'][i] = 0\n",
    "    if df.word[i].startswith('en') or df.word[i].startswith('em'):\n",
    "        final['p_en_em'][i] = 1\n",
    "    else:\n",
    "        final['p_en_em'][i] = 0\n",
    "        \n",
    "    if df.word[i].endswith('able'):\n",
    "        final['s_able'][i] = 1\n",
    "    else:\n",
    "        final['s_able'][i] = 0\n",
    "        \n",
    "    if df.word[i].endswith('al') or df.word[i].endswith('ial'):\n",
    "        final['s_al_ial'][i] = 1\n",
    "    else:\n",
    "        final['s_al_ial'][i] = 0\n",
    "        \n",
    "    if df.word[i].endswith('ed') or df.word[i].endswith('ing'):\n",
    "        final['s_ed_ing'][i] = 1\n",
    "    else:\n",
    "        final['s_ed_ing'][i] = 0\n",
    "        \n",
    "    if df.word[i].endswith('tion') or df.word[i].endswith('ion'):\n",
    "        final['s_tion_ion'][i] = 1\n",
    "    else:\n",
    "        final['s_tion_ion'][i] = 0\n",
    "    if df.word[i].endswith('est'):\n",
    "        final['s_est'][i] = 1\n",
    "    else:\n",
    "        final['s_est'][i] = 0\n",
    "    if df.word[i].endswith('less'):\n",
    "        final['s_less'][i] = 1\n",
    "    else:\n",
    "        final['s_less'][i] = 0\n",
    "    if df.word[i].endswith('e') or df.word[i].endswith('es'):\n",
    "        final['s_e_es'][i] = 1\n",
    "    else :\n",
    "        final['s_e_es'][i] = 0\n",
    "    if df.word[i].endswith('en'):\n",
    "        final['s_en'][i] = 1\n",
    "    else:\n",
    "        final['s_en'][i] = 0\n",
    "    if df.word[i].endswith('ly'):\n",
    "        final['s_ly'][i]=1\n",
    "    else:\n",
    "        final['s_ly'][i]=0\n",
    "    if df.word[i].endswith('er'):\n",
    "        final['s_er'][i] = 1 \n",
    "    else:\n",
    "        final['s_er'][i] = 0\n",
    "    if df.word[i].endswith('\\'s') or  df.word[i].endswith('s\\''):\n",
    "        final['s_\\'s_s\\''][i] = 1\n",
    "    else:\n",
    "        final['s_\\'s_s\\''][i] = 0\n",
    "    \n",
    "    if i >= 1:\n",
    "        if df.word[i-1] == 'a' or df.word[i-1] == 'an' or df.word[i-1] == 'the':\n",
    "            final['prev_word'][i] = 1\n",
    "        else:\n",
    "            final['prev_word'][i] = 0\n",
    "    else:\n",
    "        final['prev_word'][i] = 0\n",
    "        \n",
    "    final['word'][i]= df.word[i]\n",
    "    final['tag'][i]= df['pos_tag'][i]\n",
    "    \n",
    "    #if(j % 20000 == 0):\n",
    "    #    print(j)\n",
    "\n",
    "# append tks 2 mins for first 20000 and then time increases exponentially\n",
    "# fixed size array tks 10 mins for every 20k rows\n",
    "\n",
    "# NEVER EVER use append (means arraylist) when u knw array size in advance \n",
    "# performance of array is way way better than arraylist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing featurized dataframe to disk : for future use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211727, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>capitalize</th>\n",
       "      <th>digit_first</th>\n",
       "      <th>s_dig__e_alpha</th>\n",
       "      <th>p_anti</th>\n",
       "      <th>p_pre</th>\n",
       "      <th>p_un</th>\n",
       "      <th>p_dis</th>\n",
       "      <th>p_inter</th>\n",
       "      <th>...</th>\n",
       "      <th>s_ed_ing</th>\n",
       "      <th>s_tion_ion</th>\n",
       "      <th>s_est</th>\n",
       "      <th>s_less</th>\n",
       "      <th>s_e_es</th>\n",
       "      <th>s_en</th>\n",
       "      <th>s_ly</th>\n",
       "      <th>s_er</th>\n",
       "      <th>s_'s_s'</th>\n",
       "      <th>prev_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confidence</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pound</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  tag  capitalize  digit_first  s_dig__e_alpha  p_anti  p_pre  \\\n",
       "0  Confidence   NN           1            0               0       0      0   \n",
       "1          in   IN           0            0               0       0      0   \n",
       "2         the   DT           0            0               0       0      0   \n",
       "3       pound   NN           0            0               0       0      0   \n",
       "4          is  VBZ           0            0               0       0      0   \n",
       "\n",
       "   p_un  p_dis  p_inter    ...      s_ed_ing  s_tion_ion  s_est  s_less  \\\n",
       "0     0      0        0    ...             0           0      0       0   \n",
       "1     0      0        0    ...             0           0      0       0   \n",
       "2     0      0        0    ...             0           0      0       0   \n",
       "3     0      0        0    ...             0           0      0       0   \n",
       "4     0      0        0    ...             0           0      0       0   \n",
       "\n",
       "   s_e_es  s_en  s_ly  s_er  s_'s_s'  prev_word  \n",
       "0       1     0     0     0        0          0  \n",
       "1       0     0     0     0        0          0  \n",
       "2       1     0     0     0        0          0  \n",
       "3       0     0     0     0        0          1  \n",
       "4       0     0     0     0        0          0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing the featurized df to disk into csv format \n",
    "final.to_csv('./final_df_by_arr.csv',sep = ',' , index = False , encoding = 'utf-8')\n",
    "\n",
    "# reading from disk \n",
    "checkdf = pd.read_csv('./final_df.csv' , sep = ',' )\n",
    "print(checkdf.shape)\n",
    "checkdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdf['tag'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
